{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32356b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#notebook content source and project idea: https://data-flair.training/blogs/advanced-python-project-detecting-fake-news/\n",
    "#package import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9c9e314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6335, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data. personal note: pathname has to be specified all the way from Users. \n",
    "#no changing directory in jupyter notebook apparently\n",
    "df=pd.read_csv('/Users/stefbp/Desktop/bata/ML_AI/FakeNewsDetection/data/news.csv')\n",
    "\n",
    "#Get data shape and head\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e059e4f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first 5 observations\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e094524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    FAKE\n",
       "1    FAKE\n",
       "2    REAL\n",
       "3    FAKE\n",
       "4    REAL\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define labels series as the label column\n",
    "label = df.loc[:,'label']\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f56c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset. df's text column as the predictor, and the label column or variable as the dependent variable.\n",
    "#split is 80-20 train-test.\n",
    "x_train,x_test,y_train,y_test=train_test_split(df['text'], label, test_size=0.2, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c94e7f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a TfidfVectorizer\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "#stop_words arg: 'english' basically corresponds to a set of stop words. stop words (like 'and') are to be thrown out.\n",
    "#stop words must be read on later, and must be chosen appropriately according to aim.\n",
    "\n",
    "#Fit transform train set, transform test set according to tfidf_vectorizer's set parameters.\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(x_train)\n",
    "tfidf_test=tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "643b10fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5068, 61872)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c819ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1267, 61872)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_test.shape\n",
    "#kinda begs the question: what is the 61872 for the columns? the number of unique words in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "655e59ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.66%\n"
     ]
    }
   ],
   "source": [
    "#Initialize a PassiveAggressiveClassifier\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(tfidf_train,y_train)#fit the train tfidf_vectorized to the train label.\n",
    "\n",
    "#Predict with the trained passive aggressive classifier on the test set\n",
    "y_pred=pac.predict(tfidf_test)\n",
    "score=accuracy_score(y_test,y_pred)#calculate accuracy\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0831c520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[607,  38],\n",
       "       [ 55, 567]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build confusion matrix\n",
    "confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])\n",
    "#so, 603 true positives, 570 true negatives, 52 false positives, 42 false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a63456",
   "metadata": {},
   "source": [
    "okay, so the passive aggressive classifier:\n",
    "good for huge datasets since it works iteratively (get example, update model, throw away example, rinse & repeat).\n",
    "it's aggressive in that it has regularization to penalize errors, but passive when the example's prediction result is within expectations (in this case, actually being right).\n",
    "parameters: regularization parameter (how much the penalty is), max iterations (typical), and error tolerance (yeah).\n",
    "\n",
    "sources: https://www.geeksforgeeks.org/passive-aggressive-classifiers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a6c76",
   "metadata": {},
   "source": [
    "so, begs the question: how do we make it better? i think the way to crank up this accuracy:\n",
    "1. vectorize the data another way (will try this later)\n",
    "2. play around with the parameters of the passive aggressive classifier\n",
    "we'll go with no. 2 first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f6de3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iterations accuracy\n",
       "12       170.0      NaN\n",
       "13       180.0      NaN\n",
       "14       190.0      NaN\n",
       "15       200.0      NaN"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#general aim is to run the passive aggressive classifier on several different levels of regularization and max iterations.\n",
    "#will leave the error requirement alone for now.\n",
    "#start with iterations alone. i'll try between 50-200 on increments of 10 (16 levels) and make a chart of the accuracy for each point.\n",
    "trial_iter = pd.DataFrame(index=range(16),columns=range(2))\n",
    "trial_iter.columns=['iterations','accuracy']\n",
    "trial_iter['iterations'] = np.linspace(50,200,num=16)#the iterations\n",
    "trial_iter.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3088a3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in trial_iter['iterations']:\n",
    "    trial_pac=PassiveAggressiveClassifier(max_iter=iter,tol=1e-10)\n",
    "    trial_pac.fit(tfidf_train,y_train)#fit the train tfidf_vectorized to the train label.\n",
    "    trial_y_pred=pac.predict(tfidf_test)\n",
    "    trial_score=accuracy_score(y_test,trial_y_pred)#calculate accuracy\n",
    "    \n",
    "    trial_iter.loc[trial_iter['iterations'] == iter,'accuracy'] = trial_score #allocate the trial_score to its corresponding iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c955c76a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>130.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>160.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>170.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>180.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>190.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iterations  accuracy\n",
       "0         50.0  0.926598\n",
       "1         60.0  0.926598\n",
       "2         70.0  0.926598\n",
       "3         80.0  0.926598\n",
       "4         90.0  0.926598\n",
       "5        100.0  0.926598\n",
       "6        110.0  0.926598\n",
       "7        120.0  0.926598\n",
       "8        130.0  0.926598\n",
       "9        140.0  0.926598\n",
       "10       150.0  0.926598\n",
       "11       160.0  0.926598\n",
       "12       170.0  0.926598\n",
       "13       180.0  0.926598\n",
       "14       190.0  0.926598\n",
       "15       200.0  0.926598"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f901743c",
   "metadata": {},
   "source": [
    "so clearly adding iterations didnt do jack. what about regularization? i'll try it from 0.5 to 2.0 in increments of 0.1, so 16 levels again to this thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7559ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regularization</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    regularization accuracy\n",
       "12             1.7      NaN\n",
       "13             1.8      NaN\n",
       "14             1.9      NaN\n",
       "15             2.0      NaN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_reg = pd.DataFrame(index=range(16),columns=range(2))\n",
    "trial_reg.columns=['regularization','accuracy']\n",
    "trial_reg['regularization'] = np.linspace(0.5,2.0,num=16)#the iterations\n",
    "trial_reg.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2dfda2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in trial_reg['regularization']:\n",
    "    trial_pac=PassiveAggressiveClassifier(max_iter=50,C=iter)\n",
    "    trial_pac.fit(tfidf_train,y_train)#fit the train tfidf_vectorized to the train label.\n",
    "    trial_y_pred=pac.predict(tfidf_test)\n",
    "    trial_score=accuracy_score(y_test,trial_y_pred)#calculate accuracy\n",
    "    \n",
    "    trial_reg.loc[trial_reg['regularization'] == iter,'accuracy'] = trial_score #allocate the trial_score to its corresponding iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "464e2c45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regularization</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.3</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.7</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.8</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.9</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.926598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    regularization  accuracy\n",
       "0              0.5  0.926598\n",
       "1              0.6  0.926598\n",
       "2              0.7  0.926598\n",
       "3              0.8  0.926598\n",
       "4              0.9  0.926598\n",
       "5              1.0  0.926598\n",
       "6              1.1  0.926598\n",
       "7              1.2  0.926598\n",
       "8              1.3  0.926598\n",
       "9              1.4  0.926598\n",
       "10             1.5  0.926598\n",
       "11             1.6  0.926598\n",
       "12             1.7  0.926598\n",
       "13             1.8  0.926598\n",
       "14             1.9  0.926598\n",
       "15             2.0  0.926598"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d14eea2",
   "metadata": {},
   "source": [
    "separately, i did try to tighten the tolerance level up to 1e-10. same results, even with anticipation that a stricter tolerance would usually imply the need of a higher iteration limit.\n",
    "\n",
    "thus, i cant think of any way to modify the passive aggressive classifier on tf-idf vectorized data that actually increases the accuracy. will have to modify the methodology completely. thus ends the experiment here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
